{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import bayesian_changepoint_detection.online_likelihoods as online_ll\n",
    "import scipy.special as special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma(z):\n",
    "    return special.gamma(z)\n",
    "\n",
    "\n",
    "def t_pdf(x, df, loc=0, scale=1):\n",
    "    # 如果是 loc=0, scale=1，则退化为标准 t 分布\n",
    "\n",
    "    # 标准化\n",
    "    z = (x - loc) / scale\n",
    "\n",
    "    # 标准 t 分布的 PDF 系数\n",
    "    numerator = gamma((df + 1) / 2.0)\n",
    "    denominator = np.sqrt(df * np.pi) * gamma(df / 2.0)\n",
    "    coefficient = numerator / denominator\n",
    "\n",
    "    # (1 + z^2/df)^(-(df+1)/2)\n",
    "    exponent = -(df + 1) / 2.0\n",
    "    pdf_val_standard = coefficient * (1 + (z**2 / df)) ** exponent\n",
    "\n",
    "    # loc-scale变换后的 PDF: 对标准 PDF 再除以 scale\n",
    "    return pdf_val_standard / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentT:\n",
    "    def __init__(\n",
    "        self, alpha: float = 0.1, beta: float = 0.1, kappa: float = 1, mu: float = 0\n",
    "    ):\n",
    "        \"\"\"\n",
    "        StudentT distribution except normal distribution is replaced with the student T distribution\n",
    "        https://en.wikipedia.org/wiki/Normal-gamma_distribution\n",
    "\n",
    "        Parameters:\n",
    "            alpha - alpha in gamma distribution prior\n",
    "            beta - beta inn gamma distribution prior\n",
    "            mu - mean from normal distribution\n",
    "            kappa - variance from normal distribution\n",
    "        \"\"\"\n",
    "\n",
    "        self.alpha0 = self.alpha = np.array([alpha])\n",
    "        self.beta0 = self.beta = np.array([beta])\n",
    "        self.kappa0 = self.kappa = np.array([kappa])\n",
    "        self.mu0 = self.mu = np.array([mu])\n",
    "\n",
    "    def pdf(self, data: np.array):\n",
    "        \"\"\"\n",
    "        Return the pdf function of the t distribution\n",
    "\n",
    "        Parmeters:\n",
    "            data - the datapoints to be evaluated (shape: 1 x D vector)\n",
    "        \"\"\"\n",
    "        return t_pdf(\n",
    "            x=data,\n",
    "            df=2 * self.alpha,\n",
    "            loc=self.mu,\n",
    "            scale=np.sqrt(self.beta * (self.kappa + 1) / (self.alpha * self.kappa)),\n",
    "        )\n",
    "\n",
    "    def update_theta(self, data: np.array, **kwargs):\n",
    "        \"\"\"\n",
    "        Performs a bayesian update on the prior parameters, given data\n",
    "        Parmeters:\n",
    "            data - the datapoints to be evaluated (shape: 1 x D vector)\n",
    "        \"\"\"\n",
    "        muT0 = np.concatenate(\n",
    "            (self.mu0, (self.kappa * self.mu + data) / (self.kappa + 1))\n",
    "        )\n",
    "        kappaT0 = np.concatenate((self.kappa0, self.kappa + 1.0))\n",
    "        alphaT0 = np.concatenate((self.alpha0, self.alpha + 0.5))\n",
    "        betaT0 = np.concatenate(\n",
    "            (\n",
    "                self.beta0,\n",
    "                self.beta\n",
    "                + (self.kappa * (data - self.mu) ** 2) / (2.0 * (self.kappa + 1.0)),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.mu = muT0\n",
    "        self.kappa = kappaT0\n",
    "        self.alpha = alphaT0\n",
    "        self.beta = betaT0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_changepoint_detection(data, hazard_function, log_likelihood_class):\n",
    "    \"\"\"\n",
    "    Use online bayesian changepoint detection\n",
    "    https://scientya.com/bayesian-online-change-point-detection-an-intuitive-understanding-b2d2b9dc165b\n",
    "\n",
    "    Parameters:\n",
    "    data    -- the time series data\n",
    "\n",
    "    Outputs:\n",
    "        R  -- is the probability at time step t that the last sequence is already s time steps long\n",
    "        maxes -- the argmax on column axis of matrix R (growth probability value) for each time step\n",
    "    \"\"\"\n",
    "    maxes = np.zeros(len(data) + 1)\n",
    "\n",
    "    R = np.zeros((len(data) + 1, len(data) + 1))\n",
    "    R[0, 0] = 1\n",
    "\n",
    "    for t, x in enumerate(data):\n",
    "        # Evaluate the predictive distribution for the new datum under each of\n",
    "        # the parameters.  This is the standard thing from Bayesian inference.\n",
    "        predprobs = log_likelihood_class.pdf(x)\n",
    "\n",
    "        # Evaluate the hazard function for this interval\n",
    "        H = hazard_function(np.array(range(t + 1)))\n",
    "\n",
    "        # Evaluate the growth probabilities - shift the probabilities down and to\n",
    "        # the right, scaled by the hazard function and the predictive\n",
    "        # probabilities.\n",
    "        R[1 : t + 2, t + 1] = R[0 : t + 1, t] * predprobs * (1 - H)\n",
    "\n",
    "        # Evaluate the probability that there *was* a changepoint and we're\n",
    "        # accumulating the mass back down at r = 0.\n",
    "        R[0, t + 1] = np.sum(R[0 : t + 1, t] * predprobs * H)\n",
    "\n",
    "        # Renormalize the run length probabilities for improved numerical\n",
    "        # stability.\n",
    "        R[:, t + 1] = R[:, t + 1] / np.sum(R[:, t + 1])\n",
    "\n",
    "        # Update the parameter sets for each possible run length.\n",
    "        log_likelihood_class.update_theta(x, t=t)\n",
    "\n",
    "        maxes[t] = R[:, t].argmax()\n",
    "\n",
    "    return R, maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_hazard(r):\n",
    "    lam=250\n",
    "    \"\"\"\n",
    "    Hazard function for bayesian online learning\n",
    "    Arguments:\n",
    "        lam - inital prob\n",
    "        r - R matrix\n",
    "    \"\"\"\n",
    "    return 1 / lam * np.ones(r.shape)\n",
    "\n",
    "def hazard_function(r):\n",
    "    return constant_hazard(r)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10964/3799741327.py:13: RuntimeWarning: overflow encountered in multiply\n",
      "  denominator = np.sqrt(df * np.pi) * gamma(df / 2.0)\n",
      "/tmp/ipykernel_10964/3799741327.py:14: RuntimeWarning: invalid value encountered in divide\n",
      "  coefficient = numerator / denominator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R:  (582, 582)\n",
      "cps:  (array([0]),)\n",
      "R:  (206, 206)\n",
      "cps:  (array([  0,  12,  59,  74, 140]),)\n",
      "R:  (101, 101)\n",
      "cps:  (array([0]),)\n",
      "R:  (320, 320)\n",
      "cps:  (array([0]),)\n",
      "R:  (676, 676)\n",
      "cps:  (array([0]),)\n",
      "R:  (16, 16)\n",
      "cps:  (array([0]),)\n",
      "R:  (59, 59)\n",
      "cps:  (array([0]),)\n",
      "R:  (469, 469)\n",
      "cps:  (array([0]),)\n",
      "R:  (331, 331)\n",
      "cps:  (array([0]),)\n",
      "R:  (501, 501)\n",
      "cps:  (array([0]),)\n",
      "R:  (501, 501)\n",
      "cps:  (array([  0, 225]),)\n",
      "R:  (53, 53)\n",
      "cps:  (array([0]),)\n",
      "R:  (55, 55)\n",
      "cps:  (array([0]),)\n",
      "R:  (482, 482)\n",
      "cps:  (array([  0,  55,  61,  77, 185, 198, 274]),)\n",
      "R:  (193, 193)\n",
      "cps:  (array([0]),)\n",
      "Skipping multi-dimensional data:  (609, 4)\n",
      "R:  (284, 284)\n",
      "cps:  (array([ 0, 97, 98]),)\n",
      "R:  (302, 302)\n",
      "cps:  (array([0]),)\n",
      "Skipping multi-dimensional data:  (622, 2)\n",
      "Skipping multi-dimensional data:  (376, 2)\n",
      "R:  (482, 482)\n",
      "cps:  (array([  0, 106, 251, 265, 266, 280, 292, 307, 325]),)\n",
      "R:  (215, 215)\n",
      "cps:  (array([  0, 121, 131, 143, 174]),)\n",
      "R:  (59, 59)\n",
      "cps:  (array([0]),)\n",
      "R:  (216, 216)\n",
      "cps:  (array([ 0, 80, 99]),)\n",
      "R:  (469, 469)\n",
      "cps:  (array([0]),)\n",
      "R:  (38, 38)\n",
      "cps:  (array([0]),)\n",
      "Skipping multi-dimensional data:  (509, 4)\n",
      "R:  (106, 106)\n",
      "cps:  (array([], dtype=int64),)\n",
      "R:  (775, 775)\n",
      "cps:  (array([  0,  12,  13,  84, 330]),)\n",
      "R:  (367, 367)\n",
      "cps:  (array([  0, 179, 209]),)\n",
      "R:  (992, 992)\n",
      "cps:  (array([  0,  32,  86, 104, 149, 189, 212, 213, 250, 251, 277, 293, 294,\n",
      "       317]),)\n",
      "R:  (817, 817)\n",
      "cps:  (array([0]),)\n",
      "R:  (60, 60)\n",
      "cps:  (array([0]),)\n",
      "R:  (326, 326)\n",
      "cps:  (array([0]),)\n",
      "R:  (22, 22)\n",
      "cps:  (array([0, 9]),)\n",
      "R:  (25, 25)\n",
      "cps:  (array([0]),)\n",
      "R:  (601, 601)\n",
      "cps:  (array([  0, 272]),)\n",
      "R:  (314, 314)\n",
      "cps:  (array([  0, 144]),)\n",
      "R:  (248, 248)\n",
      "cps:  (array([0]),)\n",
      "R:  (200, 200)\n",
      "cps:  (array([0]),)\n",
      "R:  (119, 119)\n",
      "cps:  (array([ 0, 18, 19]),)\n",
      "R:  (105, 105)\n",
      "cps:  (array([0]),)\n"
     ]
    }
   ],
   "source": [
    "csv_folder = \"/home/campus.ncl.ac.uk/c4060464/esp32/microWATCH/datasets/csv/\"\n",
    "\n",
    "# for all files in the folder\n",
    "import os\n",
    "\n",
    "for file_name in os.listdir(csv_folder):\n",
    "    # print(\"Reading file: \", file_name)\n",
    "    file_path = csv_folder + file_name\n",
    "    data = np.loadtxt(file_path, delimiter=\",\")\n",
    "    # print(\"Data shape: \", data.shape)\n",
    "    # skip if is multi-dimensional\n",
    "    if len(data.shape) > 1:\n",
    "        print(\"Skipping multi-dimensional data: \", data.shape)\n",
    "        continue\n",
    "\n",
    "    R, maxes = online_changepoint_detection(\n",
    "        data, hazard_function, StudentT(alpha=0.1, beta=0.01, kappa=1, mu=0)\n",
    "    )\n",
    "    print(\"R: \", R.shape)\n",
    "    Nw = 10\n",
    "    cp_probs = R[Nw, Nw:-1]\n",
    "    cps = np.where(cp_probs > 0.3)\n",
    "    print(\"cps: \", cps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use scipy logsumexp().\n"
     ]
    }
   ],
   "source": [
    "from bayesian_changepoint_detection.priors import const_prior # checked\n",
    "from bayesian_changepoint_detection.offline_likelihoods import IndepentFeaturesLikelihood \n",
    "from bayesian_changepoint_detection.bayesian_models import offline_changepoint_detection\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file:  bank.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/campus.ncl.ac.uk/c4060464/esp32/microWATCH/src/algorithms/bayesian_changepoint_detection/bayesian_changepoint_detection/offline_likelihoods.py:73: RuntimeWarning: divide by zero encountered in log\n",
      "  + (N0 / 2) * np.log(V0)\n",
      "/home/campus.ncl.ac.uk/c4060464/esp32/microWATCH/src/algorithms/bayesian_changepoint_detection/bayesian_changepoint_detection/bayesian_models.py:57: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  if summand - P_next_cp < truncate:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file:  shanghai_license.csv\n",
      "Reading file:  nile.csv\n",
      "Reading file:  construction.csv\n",
      "Reading file:  well_log.csv\n",
      "Reading file:  centralia.csv\n",
      "Reading file:  gdp_japan.csv\n",
      "Reading file:  jfk_passengers.csv\n",
      "Reading file:  businv.csv\n",
      "Reading file:  quality_control_4.csv\n",
      "Reading file:  brent_spot.csv\n",
      "Reading file:  robocalls.csv\n",
      "Reading file:  ozone.csv\n",
      "Reading file:  scanline_42049.csv\n",
      "Reading file:  seatbelts.csv\n",
      "Reading file:  bee_waggle_6.csv\n",
      "Reading file:  quality_control_2.csv\n",
      "Reading file:  children_per_woman.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/campus.ncl.ac.uk/c4060464/esp32/microWATCH/src/algorithms/bayesian_changepoint_detection/bayesian_changepoint_detection/bayesian_models.py:79: RuntimeWarning: invalid value encountered in subtract\n",
      "  Pcp[j - 1, j - 1 : t]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file:  apple.csv\n",
      "Reading file:  run_log.csv\n",
      "Reading file:  scanline_126007.csv\n",
      "Reading file:  unemployment_nl.csv\n",
      "Reading file:  gdp_iran.csv\n",
      "Reading file:  co2_canada.csv\n",
      "Reading file:  lga_passengers.csv\n",
      "Reading file:  rail_lines.csv\n",
      "Reading file:  occupancy.csv\n",
      "Reading file:  uk_coal_employ.csv\n",
      "Reading file:  bitcoin.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/campus.ncl.ac.uk/c4060464/esp32/microWATCH/src/algorithms/bayesian_changepoint_detection/bayesian_changepoint_detection/bayesian_models.py:53: RuntimeWarning: invalid value encountered in logaddexp\n",
      "  P_next_cp = np.logaddexp(P_next_cp, summand)\n",
      "/home/campus.ncl.ac.uk/c4060464/esp32/microWATCH/src/algorithms/bayesian_changepoint_detection/bayesian_changepoint_detection/bayesian_models.py:69: RuntimeWarning: invalid value encountered in logaddexp\n",
      "  Q[t] = np.logaddexp(P_next_cp, P[t, n - 1] + antiG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file:  quality_control_3.csv\n",
      "Reading file:  measles.csv\n",
      "Reading file:  us_population.csv\n",
      "Reading file:  gdp_argentina.csv\n",
      "Reading file:  quality_control_5.csv\n",
      "Reading file:  debt_ireland.csv\n",
      "Reading file:  gdp_croatia.csv\n",
      "Reading file:  ratner_stock.csv\n",
      "Reading file:  quality_control_1.csv\n",
      "Reading file:  usd_isk.csv\n",
      "Reading file:  iceland_tourism.csv\n",
      "Reading file:  homeruns.csv\n",
      "Reading file:  global_co2.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "csv_folder = \"/home/campus.ncl.ac.uk/c4060464/esp32/microWATCH/datasets/csv/\"\n",
    "\n",
    "# for all files in the folder\n",
    "import os\n",
    "for file_name in os.listdir(csv_folder):\n",
    "    print(\"Reading file: \", file_name)\n",
    "    file_path = csv_folder + file_name\n",
    "    data =np.loadtxt(file_path, delimiter=',')\n",
    "\n",
    "\n",
    "    Q_ifm, P_ifm, Pcp_ifm = offline_changepoint_detection(\n",
    "        data, partial(const_prior, p=1/(len(data) + 1)), IndepentFeaturesLikelihood(), truncate=-20\n",
    "    )   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
