{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a61168e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all datasets from the \"./datasets/csv\" folder using numpy and sort by data size, then print\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "fodler_path = './datasets/csv'\n",
    "def read_and_sort_datasets(folder_path):\n",
    "    datasets = []\n",
    "    \n",
    "    # Iterate through all files in the specified folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                # Read the dataset using numpy\n",
    "                data = np.genfromtxt(file_path, delimiter=',', skip_header=1)\n",
    "                datasets.append((filename, data.shape[0]))  # Store filename and number of rows\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "    \n",
    "    # Sort datasets by the number of rows (data size)\n",
    "    datasets.sort(key=lambda x: x[1])\n",
    "    \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50944fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centralia.csv: 14 rows\n",
      "debt_ireland.csv: 20 rows\n",
      "gdp_croatia.csv: 23 rows\n",
      "rail_lines.csv: 36 rows\n",
      "robocalls.csv: 51 rows\n",
      "ozone.csv: 53 rows\n",
      "gdp_iran.csv: 57 rows\n",
      "gdp_japan.csv: 57 rows\n",
      "gdp_argentina.csv: 58 rows\n",
      "nile.csv: 99 rows\n",
      "global_co2.csv: 103 rows\n",
      "uk_coal_employ.csv: 104 rows\n",
      "homeruns.csv: 117 rows\n",
      "seatbelts.csv: 191 rows\n",
      "iceland_tourism.csv: 198 rows\n",
      "shanghai_license.csv: 204 rows\n",
      "unemployment_nl.csv: 213 rows\n",
      "co2_canada.csv: 214 rows\n",
      "usd_isk.csv: 246 rows\n",
      "quality_control_2.csv: 282 rows\n",
      "children_per_woman.csv: 300 rows\n",
      "quality_control_1.csv: 312 rows\n",
      "construction.csv: 318 rows\n",
      "quality_control_5.csv: 324 rows\n",
      "businv.csv: 329 rows\n",
      "quality_control_3.csv: 365 rows\n",
      "run_log.csv: 375 rows\n",
      "lga_passengers.csv: 467 rows\n",
      "jfk_passengers.csv: 467 rows\n",
      "scanline_42049.csv: 480 rows\n",
      "scanline_126007.csv: 480 rows\n",
      "brent_spot.csv: 499 rows\n",
      "quality_control_4.csv: 499 rows\n",
      "occupancy.csv: 508 rows\n",
      "bank.csv: 580 rows\n",
      "ratner_stock.csv: 599 rows\n",
      "bee_waggle_6.csv: 608 rows\n",
      "apple.csv: 621 rows\n",
      "well_log.csv: 674 rows\n",
      "bitcoin.csv: 773 rows\n",
      "us_population.csv: 815 rows\n",
      "measles.csv: 990 rows\n"
     ]
    }
   ],
   "source": [
    "datasets = read_and_sort_datasets(fodler_path)\n",
    "for filename, size in datasets:\n",
    "    print(f\"{filename}: {size} rows\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
